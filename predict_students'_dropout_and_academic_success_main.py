# -*- coding: utf-8 -*-
"""Predict students' dropout and academic success Main

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oexbkbnqYMCdGByyiLw_KIOdmKZ0DSKm
"""

import os
from google.colab import files
import io

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from imblearn.over_sampling import SMOTE

import warnings
warnings.filterwarnings("ignore")

colors = ['#f9fcfa','#c8ded2','#a3c8b3','#72ab8b','#4d8164','#375d47','#9467bd',"#800080"]
colors = ["#FF0000", "#00FF00", "#0000FF", "#FFA500", "#800080", "#FFFF00"]
colors2 = ['#FEE3A2','#F3C301','#87C159','#058240','#F4B183','#FD292F']

uploaded = files.upload()

df = pd.read_csv(io.BytesIO(uploaded['data.csv']), sep=";")

"""# Perform necessary data preprocessing"""

df['Target'] = df['Target'].map({'Dropout': 0, 'Graduate': 1, 'Enrolled':2})

"""# Oversample using SMOTE"""

X = df.drop('Target', axis=1)
y = df['Target']
smote = SMOTE()
X_resampled, y_resampled = smote.fit_resample(X, y)

"""# Create a new DataFrame with resampled data"""

df_resampled = pd.DataFrame(X_resampled, columns=X.columns)
df_resampled['Target'] = y_resampled

"""#Data Description"""

df_resampled.head()

df.Target.unique(), df.Target.value_counts()

df.shape

df_resampled.shape

df.info()

df.nunique()

df.describe().T

df.isnull().mean()

"""# Data Visualization and further analysis with the resampled data"""

# Explore the distribution of the target variable
plt.figure(figsize=(8, 6))
sns.countplot(x='Target', data=df_resampled)
plt.title('Distribution of Target Variable')
plt.xlabel('Target')
plt.ylabel('Count')
plt.show()

# Visualize the correlation matrix
corr_matrix = df_resampled.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=False, cmap='hot')
plt.title('Correlation Matrix')
plt.show()

# Create a bar plot for a categorical variable-##Course
plt.figure(figsize=(16,6))
sns.countplot(x='Course', data=df_resampled)
plt.title('Distribution of Courses')
plt.xlabel('Course')
plt.ylabel('Count')
plt.xticks(rotation=90)
plt.show()

# Create a bar plot for a categorical variable---Gender
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender', data=df_resampled)
plt.title('Distribution of Courses')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

#Age at enrollment
# Create a bar plot for a categorical variable---Age at enrollment
plt.figure(figsize=(8, 6))
sns.countplot(x='Age at enrollment', data=df_resampled)
plt.title('Distribution of Courses')
plt.xlabel('Age at enrollment')
plt.ylabel('Count')
plt.xticks(rotation=90)
plt.show()

# Bar plot
plt.figure(figsize=(8, 6))
sns.barplot(x="Gender", y="Target", data=df_resampled, palette="rocket")
plt.title("Bar Plot: Gender vs Target")
plt.xlabel("Gender")
plt.ylabel("Target")
plt.show()

# Count plot
plt.figure(figsize=(8, 6))
sns.countplot(x="Gender", hue="Target", data=df_resampled, palette="rocket")
plt.title("Count Plot: Gender vs Target")
plt.xlabel("Gender")
plt.ylabel("Count")
plt.show()

# Stacked bar plot
grouped_df = df.groupby(["Gender", "Target"]).size().unstack()
stacked_df = grouped_df.div(grouped_df.sum(axis=1), axis=0)
stacked_df.plot.bar(stacked=True, figsize=(8, 6), color=["#E1BEE7","#9C27B0","#4A148C"])
plt.title("Stacked Bar Plot: Gender vs Target")
plt.xlabel("Gender")
plt.ylabel("Proportion")
plt.legend(title="Target")
plt.show()

# Create a box plot for a continuous variable
plt.figure(figsize=(12, 6))
sns.boxplot(x='Course', y='Admission grade', data=df_resampled)
plt.title('Distribution of Admission Grade by Course')
plt.xlabel('Course')
plt.ylabel('Admission Grade')
plt.xticks(rotation=90)
plt.show()

# Grouped bar plot for Curricular units 1st sem variables and Target
curricular_units = [
    "Curricular units 1st sem (credited)",
    "Curricular units 1st sem (enrolled)",
    "Curricular units 1st sem (evaluations)",
    "Curricular units 1st sem (approved)",
    "Curricular units 1st sem (grade)",
    "Curricular units 1st sem (without evaluations)"
]
target_classes = df["Target"].unique()

plt.figure(figsize=(15, 12))
sns.set(style="whitegrid")

for i, curricular_unit in enumerate(curricular_units):
    plt.subplot(2, 3, i + 1)
    sns.barplot(x="Target", y=curricular_unit, data=df_resampled, ci=None)
    plt.xlabel("Target")
    plt.ylabel(curricular_unit)
    plt.title(f"{curricular_unit} by Target")

plt.tight_layout()
plt.show()

# Compute the correlation matrix
corr_matrix = df_resampled[curricular_units].corr()

# Generate the annotated heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Correlation Heatmap of Curricular Units 1st Sem")
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.show()

# Create the scatterplot matrix
sns.set(style="ticks")
sns.pairplot(df_resampled[curricular_units])
plt.show()

# Histogram
sns.histplot(data=df_resampled, x="Age at enrollment", bins=10)
plt.title("Age at Enrollment Distribution")
plt.show()

sns.histplot(data=df_resampled, x="Admission grade", bins=10)
plt.title("Admission Grade Distribution")
plt.show()

sns.histplot(data=df_resampled, x="GDP", bins=10)
plt.title("GDP Distribution")
plt.show()

# Define the variables for the line plots
x_var = "Age at enrollment"
y_var = "GDP"
facet_var = "Gender"

# Create line plots on multiple facets
sns.relplot(data=df_resampled, x=x_var, y=y_var, hue=facet_var, kind="line", height=5, aspect=1.5)

# Set labels and title
plt.xlabel(x_var)
plt.ylabel(y_var)
plt.title("Line Plot of {} by {} with Facets".format(y_var, x_var))

# Display the plot
plt.show()

# Define the variables for the line plots
x_var = "Age at enrollment"
y_var = "GDP"
facet_var = "Target"

# Create line plots on multiple facets
sns.relplot(data=df_resampled, x=x_var, y=y_var, hue=facet_var, kind="line", height=5, aspect=1.5)

# Set labels and title
plt.xlabel(x_var)
plt.ylabel(y_var)
plt.title("Line Plot of {} by {} with Facets".format(y_var, x_var))

# Display the plot
plt.show()

# Define the variables for the line plots
x_var = "Age at enrollment"
y_var = "Course"
facet_var = "Target"

# Create line plots on multiple facets
sns.relplot(data=df_resampled, x=x_var, y=y_var, hue=facet_var, kind="line", height=5, aspect=1.5)

# Set labels and title
plt.xlabel(x_var)
plt.ylabel(y_var)
plt.title("Line Plot of {} by {} with Facets".format(y_var, x_var))

# Display the plot
plt.show()

# Define the variables for the line plots
x_var = "Admission grade"
y_var = "Nacionality"
facet_var = "Target"

# Create line plots on multiple facets
sns.relplot(data=df_resampled, x=x_var, y=y_var, hue=facet_var, kind="line", height=5, aspect=1.5)

# Set labels and title
plt.xlabel(x_var)
plt.ylabel(y_var)
plt.title("Line Plot of {} by {} with Facets".format(y_var, x_var))

# Display the plot
plt.show()

"""#Compare two features w.r.t Target variable"""

columns=['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)',
                     'Curricular units 2nd sem (grade)', 'Unemployment rate', 'Inflation rate', 'GDP', 'Marital status', 'Application mode', 'Application order', 'Course',
                       'Previous qualification', 'Nacionality', "Mother's qualification",
                       "Father's qualification", "Mother's occupation", "Father's occupation",
                       'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date',
                       'Gender', 'Scholarship holder', 'Age at enrollment', 'International',
                       'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)',
                       'Curricular units 1st sem (evaluations)', 'Curricular units 1st sem (approved)',
                       'Curricular units 1st sem (grade)', 'Curricular units 1st sem (without evaluations)',
                       'Curricular units 2nd sem (credited)', 'Curricular units 2nd sem (enrolled)',
                       'Curricular units 2nd sem (evaluations)', 'Curricular units 2nd sem (approved)',
                       'Curricular units 2nd sem (grade)', 'Curricular units 2nd sem (without evaluations)',
                       'Unemployment rate', 'Inflation rate', 'GDP', 'Target']

def comp(x) :

    fig = plt.subplots(nrows = 2,ncols = 2,figsize = (20,11))
    col=columns.copy()
    col.remove(x)
    for i in range(4):
        plt.subplot(2,2,i+1)
        sns.lineplot(data = df_resampled,x =col[i] ,y = x,hue = 'Target',palette=colors2,linewidth = 4)
        plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)
        title = x + ' x ' + col[i] + ' vs Target'
        plt.title(title);
    title2 = x + ' vs other feature'
    plt.suptitle(title2)

comp('Course')

comp('Nacionality')

comp('Admission grade')

comp('Previous qualification')

Relation = df_resampled.groupby(['Nacionality','Age at enrollment'])['Course','Target'].mean().reset_index()
Relation=Relation.sort_values(by=['Target'],ascending=False).reset_index(drop=True).head(10)
Relation

plt.figure(figsize=(17,4))
sns.barplot(data = Relation,x = 'Nacionality',y = 'Course',hue = 'Target',palette=colors2[2:4])
plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)

"""#Feature Engineering"""

FE=df_resampled.copy()

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
for col in FE.columns:
    if FE[col].dtype=='object':
        FE[col]=le.fit_transform(FE[col])

"""#Scaling"""

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler() # Normalization

# Normalization
FE['Age at enrollment'] = mms.fit_transform(FE[['Age at enrollment']])
FE['Course'] = mms.fit_transform(FE[['Course']])

FE['Target']=FE['Target'].round(0)
FE['Target']=FE['Target'].astype(int)

"""#Correlation"""

corr = FE.corr()

plt.figure(figsize=(8,4))
sns.heatmap(corr, cmap="Greens", annot=False)

corr = FE.corrwith(FE['Target']).sort_values(ascending = False).to_frame()
corr.columns = ['Target']

plt.subplots(figsize = (5,5))
sns.heatmap(corr,annot = True,cmap = 'Greens',linewidths =2,linecolor = 'black');

plt.title('Target Correlation');

"""#Model"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install pycaret

from pycaret.regression import *
s = setup(data=df_resampled, target='Target', session_id=123, normalize=True,fold = 3, remove_outliers = True)

best=compare_models()

tuned_model=tune_model(best, n_iter =10)

plot_model(tuned_model, plot='feature')

"""# Split the data into features (X) and target variable (y)"""

X = df_resampled.drop("Target", axis=1)
y = df_resampled["Target"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.shape, y_train.shape)

"""#Scale the features for better model performance"""

# Scale the features using StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Classification algorithms:

1. Logistic Regression
2. Decision Tree
3. Random Forest
4. K-nearest Neighbors (KNN)
5. Bayesian Classifier
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

logreg = LogisticRegression()
logreg.fit(X_train, y_train)
logreg_pred = logreg.predict(X_test_scaled)

logreg_accuracy = accuracy_score(y_test, logreg_pred)
logreg_precision = precision_score(y_test, logreg_pred, average='macro')
logreg_recall = recall_score(y_test, logreg_pred, average='macro')
logreg_f1 = f1_score(y_test, logreg_pred, average='macro')

print("Logistic Regression:")
print("Accuracy: {:.2f}%".format(logreg_accuracy * 100))
print("Precision: {:.2f}%".format(logreg_precision * 100))
print("Recall: {:.2f}%".format(logreg_recall * 100))
print("F1-score: {:.2f}%".format(logreg_f1 * 100))
print()

from sklearn.metrics import confusion_matrix
con= confusion_matrix(y_test, logreg_pred)
sns.heatmap(con,annot=True, fmt ='d')
plt.plot()

# Decision Trees
dt = DecisionTreeClassifier()
dt.fit(X_train_scaled, y_train)
dt_pred = dt.predict(X_test_scaled)

dt_accuracy = accuracy_score(y_test, dt_pred)
dt_precision = precision_score(y_test, dt_pred, average='macro')
dt_recall = recall_score(y_test, dt_pred, average='macro')
dt_f1 = f1_score(y_test, dt_pred, average='macro')

print("Decision Trees:")
print("Accuracy: {:.2f}%".format(dt_accuracy * 100))
print("Precision: {:.2f}%".format(dt_precision * 100))
print("Recall: {:.2f}%".format(dt_recall * 100))
print("F1-score: {:.2f}%".format(dt_f1 * 100))
print()

from sklearn.metrics import confusion_matrix
con= confusion_matrix(y_test, dt_pred)
sns.heatmap(con,annot=True, fmt ='d')
plt.plot

# Random Forests
rf = RandomForestClassifier()
rf.fit(X_train_scaled, y_train)
rf_pred = rf.predict(X_test_scaled)

rf_accuracy = accuracy_score(y_test, rf_pred)
rf_precision = precision_score(y_test, rf_pred, average='macro')
rf_recall = recall_score(y_test, rf_pred, average='macro')
rf_f1 = f1_score(y_test, rf_pred, average='macro')

print("Random Forests:")
print("Accuracy: {:.2f}%".format(rf_accuracy * 100))
print("Precision: {:.2f}%".format(rf_precision * 100))
print("Recall: {:.2f}%".format(rf_recall * 100))
print("F1-score: {:.2f}%".format(rf_f1 * 100))
print()

from sklearn.metrics import confusion_matrix
con= confusion_matrix(y_test, rf_pred)
sns.heatmap(con,annot=True, fmt ='d')
plt.plot

# K-nearest Neighbors (KNN)
knn = KNeighborsClassifier()
knn.fit(X_train_scaled, y_train)
knn_pred = knn.predict(X_test_scaled)

knn_accuracy = accuracy_score(y_test, knn_pred)
knn_precision = precision_score(y_test, knn_pred, average='macro')
knn_recall = recall_score(y_test, knn_pred, average='macro')
knn_f1 = f1_score(y_test, knn_pred, average='macro')

print("K-nearest Neighbors (KNN):")
print("Accuracy: {:.2f}%".format(knn_accuracy * 100))
print("Precision: {:.2f}%".format(knn_precision * 100))
print("Recall: {:.2f}%".format(knn_recall * 100))
print("F1-score: {:.2f}%".format(knn_f1 * 100))
print()

from sklearn.metrics import confusion_matrix
con= confusion_matrix(y_test, knn_pred)
sns.heatmap(con,annot=True, fmt ='d')
plt.plot

# Bayesian Classifier
bayes = GaussianNB()
bayes.fit(X_train_scaled, y_train)
bayes_pred = bayes.predict(X_test_scaled)

bayes_accuracy = accuracy_score(y_test, bayes_pred)
bayes_precision = precision_score(y_test, bayes_pred, average='macro')
bayes_recall = recall_score(y_test, bayes_pred, average='macro')
bayes_f1 = f1_score(y_test, bayes_pred, average='macro')

print("Bayesian Classifier:")
print("Accuracy: {:.2f}%".format(bayes_accuracy * 100))
print("Precision: {:.2f}%".format(bayes_precision * 100))
print("Recall: {:.2f}%".format(bayes_recall * 100))
print("F1-score: {:.2f}%".format(bayes_f1 * 100))
print()

from sklearn.metrics import confusion_matrix
con= confusion_matrix(y_test, bayes_pred)
sns.heatmap(con,annot=True, fmt ='d')
plt.plot